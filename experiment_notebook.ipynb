{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We opt to define all the global configuration settings through this dict\n",
    "config = {\"resampling_fs\" : 22050, #expected resampling rate on HDF5 file creation\n",
    "          \"dst_path\":\"./choral_dst\", # User Dataset path (if None, the default one will be used)\n",
    "          \"hdf5_filepath\":\"./choral_dst.hdf5\"\n",
    "         }\n",
    "\n",
    "if not os.path.isdir('./debug'):\n",
    "    os.mkdir('./debug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Data Handling Methodology</center></h1>\n",
    "\n",
    "For the first step of this task, we will work from the __Choral Singing Dataset__, which contains three choir songs composed of 4 groups of 4 singers (16 parts per song), for a total of 48 stems. The dataset can be downloaded from Zenodo at the following:\n",
    "\n",
    "https://zenodo.org/record/2649950#.XlJRNy2ZPRY\n",
    "\n",
    "If you happen to already have the dataset locally, please define it's local path through the ***dst_path*** variable. Otherwise, the cell below will take care of downloading it for you:\n",
    "\n",
    "### 1. Dataset Download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Path Defined. Dataset Expected to be Found at the Following:\n",
      "./choral_dst\n"
     ]
    }
   ],
   "source": [
    "#This cell downloads the Mridangam Stroke Dataset in its entirety\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os, sys,shutil\n",
    "\n",
    "#Link for the dataset. If you already have the dataset locally, define its location through the config dict above \n",
    "url = 'https://zenodo.org/record/2649950/files/ChoralSingingDataset.zip'\n",
    "\n",
    "if config[\"dst_path\"] == None:\n",
    "    main_data_dir = './choral_dst'\n",
    "    if not os.path.exists(main_data_dir): #creating the directory if not exist\n",
    "        os.mkdir(main_data_dir)\n",
    "    print('Downloading Choral Singing Dataset Dataset...')\n",
    "    foldername = url.split('/')[-1]\n",
    "    urllib.request.urlretrieve(url,foldername)\n",
    "    #Unzipping to a specific folder\n",
    "    zip_ref = zipfile.ZipFile(foldername, 'r')\n",
    "    zip_ref.extractall(main_data_dir)\n",
    "    zip_ref.close()\n",
    "    os.remove(foldername)#Removing the zip file\n",
    "    print('Data downloaded and unzipped to: ',main_data_dir)\n",
    "else:\n",
    "    print('User Path Defined. Dataset Expected to be Found at the Following:\\n'+config[\"dst_path\"])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Storing our Data in a Convenient Format\n",
    "\n",
    "For the sake of simplicity and clarity, we will store our song stems in a **HDF5 file**, which will help us to manage the later steps a bit more easily. This hierarchical file format will allow us to store our data in an intuitive way as follow:\n",
    "\n",
    "**[HDF5_File] -> [Set] -> [Part] -> [Song]**\n",
    "\n",
    "Since our dataset is of *very* limited size, we will break it down as follow:\n",
    "\n",
    "| Set   | Stems | Songs |\n",
    "| :---:   | :---: | :---: |\n",
    "| Train |    24   |    A, B   |\n",
    "| Valid |   8    |   A, B    |\n",
    "| Test  |16| C |\n",
    "\n",
    "**Note:** By default, the Choral Singing Dataset follow the following naming convention:\n",
    "\n",
    "*DatasetName_SongAcronym_PartName_PartNumber.wav*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 Already Exists. File Expected to be Found at the Following:\n",
      "./choral_dst.hdf5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import librosa\n",
    "import soundfile\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "\n",
    "# First check if HDF5 already exists:\n",
    "hdf5_file = Path(config['hdf5_filepath'])\n",
    "if not hdf5_file.is_file():\n",
    "    tracks = dict()\n",
    "    resampling_fs = config['resampling_fs']\n",
    "    dst_path = './choral_dst' if (config['dst_path'] == None) else config['dst_path']\n",
    "\n",
    "    # Get all the stem files\n",
    "    dst_stems = glob.glob(dst_path+\"/*.wav\",recursive=False)\n",
    "    # Extract only songs from name\n",
    "    songs = set([os.path.splitext(os.path.basename(i))[0].split('_')[1] for i in dst_stems])\n",
    "    # Take 2/3 of songs for train/valid\n",
    "    train_val_songs = random.sample(songs, int(np.ceil(0.666*len(songs))))\n",
    "    # Take the rest as test set\n",
    "    test_song = list(set(songs) - set(train_val_songs))\n",
    "    test_idx = [int(i) for i, track in enumerate(dst_stems) if [True for song in test_song if str('_'+song+'_') in track]]\n",
    "    # Take one random group of singer per song for each song as validation set\n",
    "    rand_part = random.randint(1,4)\n",
    "    val_idx   = [int(i) for i, track in enumerate(dst_stems) if [True for song in train_val_songs if ((str('_'+song+'_') in track) and (str('_'+str(rand_part)+'.wav')) in track)]]\n",
    "    # Deduce the train set from valid / test set\n",
    "    train_idx = list(set(range(len(dst_stems))) -  (set(val_idx + test_idx)))\n",
    "\n",
    "    # tracks['train'] = np.take(dst_stems, train_idx)\n",
    "    tracks['train'] = np.take(dst_stems, train_idx)\n",
    "    tracks['valid'] = np.take(dst_stems, val_idx)\n",
    "    tracks['test'] = np.take(dst_stems, test_idx)\n",
    "\n",
    "    print('Ready to create HDF5')\n",
    "\n",
    "    h5file = h5py.File(config[\"hdf5_filepath\"], \"w\")\n",
    "\n",
    "    # Write stems to hdf5 file for train/valid/test partitions\n",
    "    for curr_partition in [\"train\", \"valid\", \"test\"]:\n",
    "\n",
    "        print(\"Writing \" + curr_partition + \" partition with \"+str(len(tracks[curr_partition]))+\" files...\")\n",
    "\n",
    "        stem_list = tracks[curr_partition]\n",
    "\n",
    "        # Create group for set if needed\n",
    "        if not str(curr_partition) in h5file:\n",
    "            set_grp  = h5file.create_group(curr_partition)\n",
    "\n",
    "        sleep(1)\n",
    "\n",
    "        for track in tqdm(stem_list):\n",
    "\n",
    "            filename = os.path.splitext(os.path.basename(track))[0].split('_')\n",
    "\n",
    "            song = filename[1]\n",
    "            part = ''.join(filename[2:4])\n",
    "\n",
    "            # Create group for the Song if needed\n",
    "            if not str(curr_partition+'/'+song) in h5file:\n",
    "                song_grp  = set_grp.create_group(song)\n",
    "\n",
    "            # Create group for the Part if needed\n",
    "            if not str(curr_partition+'/'+song+'/'+part) in h5file:\n",
    "                part_grp = h5file[str(curr_partition+'/'+song)]\n",
    "                subgrp  = part_grp.create_group(part)\n",
    "\n",
    "            # Once part groups / song subgroups are created, store file\n",
    "            audio, s = librosa.load(track, sr=resampling_fs)\n",
    "            subgrp = h5file[str(curr_partition+'/'+song+'/'+part)]\n",
    "            subgrp.create_dataset(\"raw_wav\",data=audio)\n",
    "\n",
    "    print('Done Creating HDF5 at path: '+config['hdf5_filepath'])\n",
    "    h5file.close()\n",
    "else:\n",
    "    print('HDF5 Already Exists. File Expected to be Found at the Following:\\n'+config[\"hdf5_filepath\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining the Generator Function:\n",
    "\n",
    "Instead of computing features on the entirety of each of these songs, we will create many song snippets (or frames), which will depict different possible musical settings (SAT, ATB, SB, etc.) out of the songs. This will allow us to cover all possible singer permutations on a per-frame basis, without having to compute and feed to the model substantial chunk of audio.\n",
    "\n",
    "The next step would be to define the function that will generate these song frames for us. \n",
    "\n",
    "**Note:** This function will yield the song segments but won't render them to disk. We can proceed by computing everything on the fly and save ourselves some local memory space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchGenerator(hdf5_filepath, batch_size, num_frames, partition='train',debug=False):\n",
    "    \n",
    "    dataset   = h5py.File(hdf5_filepath, \"r\")\n",
    "    itCounter = 0\n",
    "\n",
    "    itCounter = itCounter + 1\n",
    "    \n",
    "    # Choose random song and retrieve all available part for it\n",
    "    randsong = random.choice(list(dataset[partition].keys())) # Get random song from dataset keys\n",
    "    sources  = list(dataset[partition][randsong].keys())      # Get all available sources for song\n",
    "    \n",
    "    # Compute available parts per group\n",
    "    part_per_group = dict({'soprano':None,'alto':None,'tenor':None,'bass':None})\n",
    "    for group in part_per_group.keys():\n",
    "        parts = [source[-1] for source in sources if group in source]\n",
    "        part_per_group[group] = parts\n",
    "\n",
    "    # Init the start/end values of song snippet\n",
    "    startspl = 0\n",
    "    endspl   = 0\n",
    "\n",
    "    # Preping the output shape of the generator\n",
    "    out_shapes = {'mix':np.zeros((batch_size, num_frames)),'num_sing':np.zeros((batch_size))}\n",
    "\n",
    "    # Will create batch_size x mixes of unique singers permutations\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        randsources = random.sample(part_per_group.keys(), random.randint(1,4)) # Randomize source pick\n",
    "\n",
    "        # Get Start and End samples. Pick random part to calculate start/end spl\n",
    "        randpart = random.choice(sources)\n",
    "        startspl = random.randint(0,len(dataset[partition][randsong][randpart]['raw_wav'])-num_frames) # This assume that all stems are the same length\n",
    "        endspl   = startspl+num_frames\n",
    "\n",
    "        # Get Random Sources with part number: \n",
    "        randsources_with_part = [\"{}{}\".format(a, random.choice(part_per_group[a])) for a in randsources] # Concatenate strings for part name\n",
    "        # Retrieve the chunks and store them in output shapes                                         \n",
    "        for source in randsources_with_part:\n",
    "\n",
    "            source_chunk = dataset[partition][randsong][source]['raw_wav'][startspl:endspl]              # Retrieve part's chunk\n",
    "            out_shapes['mix'][i] = np.add(out_shapes['mix'][i],source_chunk)            # Add the chunk to the mix\n",
    "\n",
    "        # Scale down the mix based off number of sources\n",
    "        scaler = len(randsources_with_part)\n",
    "        out_shapes['mix'][i] = (out_shapes['mix'][i]/scaler)\n",
    "        out_shapes['num_sing'][i] = len(randsources_with_part)\n",
    "\n",
    "    # if debug == True, pick one random mix from batch and synthesize it\n",
    "    if debug==True:\n",
    "\n",
    "        if partition=='train':\n",
    "            rand_pick = random.randint(0,batch_size-1)\n",
    "            debug_dir = './debug/it#'+str(itCounter)+'_batchpick#'+str(rand_pick)\n",
    "            if not os.path.isdir(debug_dir):\n",
    "                os.mkdir(debug_dir)\n",
    "            soundfile.write(debug_dir+'/'+'mix_'+str(out_shapes['num_sing'][rand_pick])+'_singers_'+'.wav', out_shapes['mix'][rand_pick], resampling_fs, 'PCM_24')\n",
    "\n",
    "batchGenerator(config['hdf5_filepath'], 16, 8192, partition='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the generator function returns a dictionary of shape:<br>\n",
    "```out_shapes = {'mix':np.zeros((batch_size, num_frames)),'num_sing':np.zeros((batch_size))}``` <br><br>where:\n",
    "* the key ```'mix'``` holds ```<batch_size>``` number of snippet of size ```<num_frames>```\n",
    "* the key ```'num_sing'``` holds the ground truth respective to each of these mixes\n",
    "\n",
    "<br>The purpose of the generator function is to provide the time-domain snippets. For the pre-processing steps related to frequency-domain conversion, see the next section below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Pre-processing Steps</center></h1>\n",
    "\n",
    "The first step of our experiment entails training a deep neural network model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
